{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nukimayasari/scraping-translating-soto-recipe?scriptVersionId=219835409\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"318da442","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-01-29T20:09:35.880533Z","iopub.status.busy":"2025-01-29T20:09:35.880047Z","iopub.status.idle":"2025-01-29T20:09:36.974571Z","shell.execute_reply":"2025-01-29T20:09:36.973307Z"},"papermill":{"duration":1.103031,"end_time":"2025-01-29T20:09:36.977103","exception":false,"start_time":"2025-01-29T20:09:35.874072","status":"completed"},"tags":[]},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","id":"1880233f","metadata":{"papermill":{"duration":0.006366,"end_time":"2025-01-29T20:09:36.990388","exception":false,"start_time":"2025-01-29T20:09:36.984022","status":"completed"},"tags":[]},"source":["# Scraping and Translating Indonesian Soto Recipes from Cookpad\n","\n","## Introduction\n","\n","**Soto**, an iconic Indonesian soup dish, is beloved for its flavorful broth and unique combinations of ingredients. Recipes for Soto vary across regions, with each version offering a distinct taste and story. With abundant Soto recipes available online, wouldn't it be exciting to scrape and analyze these recipes to uncover patterns and insights?\n","\n","In this notebook, we will explore how to scrape Soto recipes from Cookpad, a popular recipe-sharing platform, translate them into English, and extract structured information for further analysis. This step-by-step guide combines web scraping, data cleaning, and translation, making it an excellent learning resource for beginners and enthusiasts. This project is developed with the assistance of DeepSeek and ChatGPT.\n","\n","## Objectives\n","* **Scrape Recipes:** Collect Soto recipe data, including names, ingredient lists, and URLs, from Cookpad.\n","* **Extract Details:** Parse and structure the scraped information into a DataFrame.\n","* Translate Ingredients:** Use a translation API to translate Indonesian ingredient names into English.\n","* **Create a Dataset:** Save the processed data into a CSV file for easy sharing and future analysis.\n","\n","## Tools and Libraries\n","We will use the following Python libraries:\n","* **`requests`**: To fetch HTML content from web pages.\n","* **`BeautifulSoup`**: For parsing and extracting structured data from the HTML.\n","* **`pandas`**: To organize and manipulate data in tabular form.\n","* **`deep-translator`**: For translating text using Google Translate.\n","\n","Before running the code, make sure you have installed these libraries:"]},{"cell_type":"code","execution_count":2,"id":"a465d595","metadata":{"execution":{"iopub.execute_input":"2025-01-29T20:09:37.006422Z","iopub.status.busy":"2025-01-29T20:09:37.00583Z","iopub.status.idle":"2025-01-29T20:09:42.804375Z","shell.execute_reply":"2025-01-29T20:09:42.802984Z"},"papermill":{"duration":5.808618,"end_time":"2025-01-29T20:09:42.806445","exception":false,"start_time":"2025-01-29T20:09:36.997827","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\r\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\r\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\r\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\r\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\r\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\r\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\r\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\r\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\r\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.3.8)\r\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.2.4)\r\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (0.1.1)\r\n","Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2025.0.1)\r\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2022.0.0)\r\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2.4.1)\r\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n","Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2024.2.0)\r\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2022.0.0)\r\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas) (1.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas) (2024.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas) (2024.2.0)\r\n"]}],"source":["!pip install requests beautifulsoup4 pandas"]},{"cell_type":"code","execution_count":3,"id":"04470183","metadata":{"execution":{"iopub.execute_input":"2025-01-29T20:09:42.816612Z","iopub.status.busy":"2025-01-29T20:09:42.816182Z","iopub.status.idle":"2025-01-29T20:09:43.315709Z","shell.execute_reply":"2025-01-29T20:09:43.31444Z"},"papermill":{"duration":0.506949,"end_time":"2025-01-29T20:09:43.317803","exception":false,"start_time":"2025-01-29T20:09:42.810854","status":"completed"},"tags":[]},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd"]},{"cell_type":"markdown","id":"42482904","metadata":{"papermill":{"duration":0.004406,"end_time":"2025-01-29T20:09:43.326631","exception":false,"start_time":"2025-01-29T20:09:43.322225","status":"completed"},"tags":[]},"source":["## Steps\n","\n","### Step 1: Scraping Cookpad Recipes\n","\n","We start by building a **scraper** to collect Soto recipes from Cookpad. The scraper navigates through multiple pages, fetching the recipe names and URLs."]},{"cell_type":"code","execution_count":4,"id":"c743cf76","metadata":{"execution":{"iopub.execute_input":"2025-01-29T20:09:43.336609Z","iopub.status.busy":"2025-01-29T20:09:43.335944Z","iopub.status.idle":"2025-01-29T20:09:43.342368Z","shell.execute_reply":"2025-01-29T20:09:43.341337Z"},"papermill":{"duration":0.013265,"end_time":"2025-01-29T20:09:43.344082","exception":false,"start_time":"2025-01-29T20:09:43.330817","status":"completed"},"tags":[]},"outputs":[],"source":["def scrape_cookpad(query, num_pages=5):\n","    base_url = \"https://cookpad.com/id/cari/\"\n","    headers = {\n","        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n","    }\n","    recipes = []\n","    \n","    for page in range(1, num_pages + 1):\n","        url = f\"{base_url}{query}?page={page}\"\n","        response = requests.get(url, headers=headers)\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","        \n","        # Debugging: Print the soup to check structure\n","        # print(soup.prettify())\n","        \n","        for recipe in soup.find_all('a', class_='block-link__main'):  # Update class here if needed\n","            recipe_name = recipe.text.strip()\n","            recipe_url = \"https://cookpad.com\" + recipe['href']\n","            recipes.append((recipe_name, recipe_url))\n","    \n","    return recipes"]},{"cell_type":"markdown","id":"36b693e1","metadata":{"papermill":{"duration":0.003726,"end_time":"2025-01-29T20:09:43.352695","exception":false,"start_time":"2025-01-29T20:09:43.348969","status":"completed"},"tags":[]},"source":["### Step 2: Extracting Recipe Details\n","\n","Next, we fetch individual recipe pages to extract the recipe title and list of ingredients. Each recipe will be stored in a structured format."]},{"cell_type":"code","execution_count":5,"id":"0aa63f0b","metadata":{"execution":{"iopub.execute_input":"2025-01-29T20:09:43.362576Z","iopub.status.busy":"2025-01-29T20:09:43.362177Z","iopub.status.idle":"2025-01-29T20:09:43.369494Z","shell.execute_reply":"2025-01-29T20:09:43.368003Z"},"papermill":{"duration":0.014655,"end_time":"2025-01-29T20:09:43.371442","exception":false,"start_time":"2025-01-29T20:09:43.356787","status":"completed"},"tags":[]},"outputs":[],"source":["def get_recipe_details(url):\n","    headers = {\n","        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n","    }\n","    response = requests.get(url, headers=headers)\n","    soup = BeautifulSoup(response.text, 'html.parser')\n","    \n","    # Extract ingredients\n","    ingredients = []\n","    ingredient_section = soup.find('div', class_='ingredient-list')  # Update based on actual structure\n","    if ingredient_section:\n","        for li in ingredient_section.find_all('li'):\n","            ingredients.append(li.text.strip())\n","    \n","    # Extract recipe title (Soto)\n","    title_element = soup.find('h1')  # Try without specifying class first\n","    recipe_title = title_element.text.strip() if title_element else \"Unknown\"\n","    \n","    return {\n","        'Soto': recipe_title,\n","        'Ingredients': ingredients,\n","        'Link Source': url\n","    }\n"]},{"cell_type":"code","execution_count":6,"id":"91b77383","metadata":{"execution":{"iopub.execute_input":"2025-01-29T20:09:43.381645Z","iopub.status.busy":"2025-01-29T20:09:43.381259Z","iopub.status.idle":"2025-01-29T20:10:50.94416Z","shell.execute_reply":"2025-01-29T20:10:50.942919Z"},"papermill":{"duration":67.574428,"end_time":"2025-01-29T20:10:50.950254","exception":false,"start_time":"2025-01-29T20:09:43.375826","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["                               Soto  \\\n","0  Soto Ayam Rumahan /Soto Lamongan   \n","1       Rujak soto Bwi (Banyuwangi)   \n","2                    Soto Mie Bogor   \n","3                  Soto Ayam Santan   \n","4      Soto Betawi kuah santan susu   \n","\n","                                         Ingredients  \\\n","0  [Bahan utama:, 1 Kg dada ayam, 1/4 kg telur, 1...   \n","1  [1/4 kg babat sapi dibersihkan sampai putih de...   \n","2  [500 gr daging sapi (saya pilih sandung lamur)...   \n","3  [1/2 kg ayam (aku pakai paha), 10 btr bwg mera...   \n","4  [700 gr daging, 2 buah wortel, 2 buah kentang,...   \n","\n","                                         Link Source  \n","0  https://cookpad.com/id/resep/24445055-soto-aya...  \n","1  https://cookpad.com/id/resep/24444549-rujak-so...  \n","2  https://cookpad.com/id/resep/24441258-soto-mie...  \n","3  https://cookpad.com/id/resep/24441246-soto-aya...  \n","4  https://cookpad.com/id/resep/24437089-soto-bet...  \n"]}],"source":["# Scrape Soto recipes\n","soto_recipes = scrape_cookpad(\"soto\")\n","\n","# Extract details for all recipes\n","recipe_details = []\n","for name, url in soto_recipes:\n","    try:\n","        details = get_recipe_details(url)\n","        recipe_details.append(details)\n","    except Exception as e:\n","        print(f\"Error scraping {url}: {e}\")\n","\n","# Create a DataFrame\n","df = pd.DataFrame(recipe_details)\n","\n","# Display the DataFrame\n","print(df.head())"]},{"cell_type":"code","execution_count":7,"id":"286a5bc0","metadata":{"execution":{"iopub.execute_input":"2025-01-29T20:10:50.959874Z","iopub.status.busy":"2025-01-29T20:10:50.959497Z","iopub.status.idle":"2025-01-29T20:10:50.966096Z","shell.execute_reply":"2025-01-29T20:10:50.964978Z"},"papermill":{"duration":0.01315,"end_time":"2025-01-29T20:10:50.967669","exception":false,"start_time":"2025-01-29T20:10:50.954519","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(150, 3)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"markdown","id":"92db3b1c","metadata":{"papermill":{"duration":0.004072,"end_time":"2025-01-29T20:10:50.976218","exception":false,"start_time":"2025-01-29T20:10:50.972146","status":"completed"},"tags":[]},"source":["### Step 3: Translating Ingredients\n","\n","Most of the ingredients are in Indonesian, so we use **deep-translator** to translate them into English. To speed up the process, we implement a translation **cache** to avoid redundant API calls."]},{"cell_type":"code","execution_count":8,"id":"d4fddd8b","metadata":{"execution":{"iopub.execute_input":"2025-01-29T20:10:50.986473Z","iopub.status.busy":"2025-01-29T20:10:50.986054Z","iopub.status.idle":"2025-01-29T20:10:55.779253Z","shell.execute_reply":"2025-01-29T20:10:55.777522Z"},"papermill":{"duration":4.800826,"end_time":"2025-01-29T20:10:55.781336","exception":false,"start_time":"2025-01-29T20:10:50.98051","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting deep-translator\r\n","  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\r\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (4.12.3)\r\n","Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (2.32.3)\r\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.6)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.0)\r\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.10)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.2.3)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.12.14)\r\n","Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hInstalling collected packages: deep-translator\r\n","Successfully installed deep-translator-1.11.4\r\n"]}],"source":["!pip install deep-translator"]},{"cell_type":"code","execution_count":9,"id":"1395adc6","metadata":{"execution":{"iopub.execute_input":"2025-01-29T20:10:55.792518Z","iopub.status.busy":"2025-01-29T20:10:55.792137Z","iopub.status.idle":"2025-01-29T20:52:24.761598Z","shell.execute_reply":"2025-01-29T20:52:24.760169Z"},"papermill":{"duration":2488.98322,"end_time":"2025-01-29T20:52:24.769419","exception":false,"start_time":"2025-01-29T20:10:55.786199","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["                               Soto  \\\n","0  Soto Ayam Rumahan /Soto Lamongan   \n","1       Rujak soto Bwi (Banyuwangi)   \n","2                    Soto Mie Bogor   \n","3                  Soto Ayam Santan   \n","4      Soto Betawi kuah santan susu   \n","\n","                                              Recipe  \\\n","0  [Bahan utama:, 1 Kg dada ayam, 1/4 kg telur, 1...   \n","1  [1/4 kg babat sapi dibersihkan sampai putih de...   \n","2  [500 gr daging sapi (saya pilih sandung lamur)...   \n","3  [1/2 kg ayam (aku pakai paha), 10 btr bwg mera...   \n","4  [700 gr daging, 2 buah wortel, 2 buah kentang,...   \n","\n","                                         Link Source  \\\n","0  https://cookpad.com/id/resep/24445055-soto-aya...   \n","1  https://cookpad.com/id/resep/24444549-rujak-so...   \n","2  https://cookpad.com/id/resep/24441258-soto-mie...   \n","3  https://cookpad.com/id/resep/24441246-soto-aya...   \n","4  https://cookpad.com/id/resep/24437089-soto-bet...   \n","\n","                                      Recipe_English  \n","0  [The main ingredient:, 1 Kg chicken breast, 1/...  \n","1  [1/4 kg of beef tripe, cleaned until white by ...  \n","2  [500 gr beef (I chose brisket), 1 piece of ric...  \n","3  [1/2 kg chicken (I used thigh), 10 pcs red bwg...  \n","4  [700 gr meat, 2 carrots, 2 potatoes, 1 tomato,...  \n"]}],"source":["from deep_translator import GoogleTranslator\n","\n","# Initialize a translation cache\n","translation_cache = {}\n","\n","def translate_with_cache(ingredient):\n","    \"\"\"\n","    Translate a single ingredient using GoogleTranslator with caching.\n","    \"\"\"\n","    # Check if the ingredient is already in the cache\n","    if ingredient in translation_cache:\n","        return translation_cache[ingredient]\n","    try:\n","        # Translate the ingredient and store it in the cache\n","        translated = GoogleTranslator(source='id', target='en').translate(ingredient)\n","        translation_cache[ingredient] = translated\n","        return translated\n","    except Exception as e:\n","        print(f\"Error translating ingredient: {ingredient}. Error: {e}\")\n","        # Return the original ingredient if translation fails\n","        return ingredient\n","\n","def translate_recipe(recipe):\n","    \"\"\"\n","    Translate all ingredients in a recipe using the translation cache.\n","    \"\"\"\n","    recipe_translated = [translate_with_cache(ingredient) for ingredient in recipe]\n","    return recipe_translated\n","\n","# Rename the current \"Ingredients\" column to \"Recipe\"\n","df.rename(columns={\"Ingredients\": \"Recipe\"}, inplace=True)\n","\n","# Create a new column \"Recipe_English\" with translated ingredients\n","df['Recipe_English'] = df['Recipe'].apply(translate_recipe)\n","\n","# Display the updated DataFrame\n","print(df.head())\n"]},{"cell_type":"markdown","id":"e3e90501","metadata":{"papermill":{"duration":0.004619,"end_time":"2025-01-29T20:52:24.77935","exception":false,"start_time":"2025-01-29T20:52:24.774731","status":"completed"},"tags":[]},"source":["### Step 4: Saving the Dataset\n","\n","Finally, we save the processed data to a **CSV file** for further analysis or sharing."]},{"cell_type":"code","execution_count":10,"id":"f314c94a","metadata":{"execution":{"iopub.execute_input":"2025-01-29T20:52:24.791757Z","iopub.status.busy":"2025-01-29T20:52:24.791384Z","iopub.status.idle":"2025-01-29T20:52:24.813122Z","shell.execute_reply":"2025-01-29T20:52:24.811904Z"},"papermill":{"duration":0.030828,"end_time":"2025-01-29T20:52:24.815477","exception":false,"start_time":"2025-01-29T20:52:24.784649","status":"completed"},"tags":[]},"outputs":[],"source":["df.to_csv(\"Soto_Recipe_Cookpad\")"]},{"cell_type":"markdown","id":"230c2ccb","metadata":{"papermill":{"duration":0.006178,"end_time":"2025-01-29T20:52:24.830541","exception":false,"start_time":"2025-01-29T20:52:24.824363","status":"completed"},"tags":[]},"source":["## Results\n","\n","The resulting DataFrame contains the following columns:\n","* **Soto:** Recipe title\n","* **Recipe:** Original ingredient list in Indonesian\n","* **Link Source:** URL to the original recipe on Cookpad\n","* **Recipe_English:** Translated ingredient list in English"]},{"cell_type":"markdown","id":"ceca015f","metadata":{"papermill":{"duration":0.004547,"end_time":"2025-01-29T20:52:24.839935","exception":false,"start_time":"2025-01-29T20:52:24.835388","status":"completed"},"tags":[]},"source":["## Key Takeaways\n","\n","* This project demonstrates how to combine web scraping and translation APIs to create a structured dataset from unstructured web data.\n","* You can adapt this workflow to scrape and analyze recipes for other dishes or from other platforms.\n","* The final dataset can be used for exploratory data analysis, ingredient frequency analysis, or even building recommendation systems for recipe enthusiasts."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":2572.612479,"end_time":"2025-01-29T20:52:25.572301","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-01-29T20:09:32.959822","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}